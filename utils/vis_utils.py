import imageio
import os
import re
import numpy as np
import torch
from utils.metrics import *
from utils.pose_utils import *
from PIL import Image, ImageDraw, ImageFont
from easydict import EasyDict as edict

def generate_video_from_images(image_directory, output_file='output.mp4', fps=50):
    # List all image files in the directory
    image_files = [os.path.join(image_directory, f) for f in os.listdir(image_directory) if f.endswith(".png")]
    image_files.sort(key=lambda x: os.path.getctime(x)) # NOTE: our png files are generated by timestamp, not by filename, such as 9_0.png && 91_0.png

    # Create an empty list to store the image frames
    frames = []

    # Read each image file and append it to the frames list
    for image_file in image_files:
        frames.append(imageio.imread(image_file))

    # Write the frames to an MP4 video file
    imageio.mimwrite(os.path.join(image_directory, output_file), frames, fps=fps)


def generate_comparision_video(d1, d2):
    
    i1 = [os.path.join(d1, f) for f in os.listdir(d1) if f.endswith(".png") and f.startswith("test_")]
    i1.sort(key=lambda x: os.path.getctime(x))
    
    i2 = [os.path.join(d2, f) for f in os.listdir(d2) if f.endswith(".png") and f.startswith("test_")]
    i2.sort(key=lambda x: os.path.getctime(x))
    
    frames = []

    length = min(len(i1), len(i2), 40)
    
    def psnr(img1):
        h, w2, c = img1.shape
        w = w2 // 2
        t1 = img1[:, :w, :].float()
        t2 = img1[:, w:w2, :].float()
        psnr1 = compute_psnr(t1, t2)
        return psnr1.item()
    
    for i in range(length):
        img1 = torch.from_numpy(np.array(imageio.imread(i1[i]))) # (h, 2w, c)
        img2 = torch.from_numpy(np.array(imageio.imread(i2[i]))) # (h, 2w, c)
        
        ### concat to comparable images
        h, w2, c = img1.shape
        w = w2 // 2
        img = torch.cat([img1[:, :w, :], img2[:, :w, :], img1[:, w:w2, :]], dim=1).numpy() # (h, 3w, c)
        
        ### find last iteration as text
        last_slash_index = i1[i].rfind('/')
        substring = i1[i][last_slash_index + 1:]
        match = re.search(r'\d+', substring)
        if match:
            text = "Iteration: {}".format(match.group())
            
        ### compute psnr as other two text
        psnr1 = psnr(img1)
        psnr2 = psnr(img2)
        text_psnr1 = "{:.3f}".format(psnr1)
        text_psnr2 = "{:.3f}".format(psnr2)

        ### add all text on image
        pil_img = Image.fromarray(img)
        draw = ImageDraw.Draw(pil_img)
        font = ImageFont.truetype('/usr/share/fonts/truetype/ubuntu/UbuntuMono-RI.ttf', size = 75)
        font2 = ImageFont.truetype('/usr/share/fonts/truetype/ubuntu/UbuntuMono-RI.ttf', size = 50)
        
        ### position of texts
        postion_iteration = (img1.shape[1]/2-200, img1.shape[0]-100)
        position_psnr1 = (0, 0)
        position_psnr2 = (img1.shape[1]/2, 0)
        
        ### let psnr winner's color be red
        color_psnr1 = (255, 0, 0) if psnr1 > psnr2 else (0, 0, 0)
        color_psnr2 = (0, 0, 0) if psnr1 > psnr2 else (255, 0, 0)
        
        ### draw text
        white_color = (0, 0, 0)
        draw.text(postion_iteration, text, white_color, font2)
        draw.text(position_psnr1, text_psnr1, color_psnr1, font)
        draw.text(position_psnr2, text_psnr2, color_psnr2, font)

        modified_img = np.array(pil_img)
        frames.append(modified_img)

    imageio.mimwrite(os.path.join(image_directory, output_file), frames, fps=1)
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d.art3d import Poly3DCollection

def setup_3D_plot(ax,elev,azim,lim=None):
    ax.xaxis.set_pane_color((1.0,1.0,1.0,0.0))
    ax.yaxis.set_pane_color((1.0,1.0,1.0,0.0))
    ax.zaxis.set_pane_color((1.0,1.0,1.0,0.0))
    ax.xaxis._axinfo["grid"]["color"] = (0.9,0.9,0.9,1)
    ax.yaxis._axinfo["grid"]["color"] = (0.9,0.9,0.9,1)
    ax.zaxis._axinfo["grid"]["color"] = (0.9,0.9,0.9,1)
    ax.xaxis.set_tick_params(labelsize=8)
    ax.yaxis.set_tick_params(labelsize=8)
    ax.zaxis.set_tick_params(labelsize=8)
    ax.set_xlabel("X",fontsize=16)
    ax.set_ylabel("Y",fontsize=16)
    ax.set_zlabel("Z",fontsize=16)
    ax.set_xlim(lim.x[0],lim.x[1])
    ax.set_ylim(lim.y[0],lim.y[1])
    ax.set_zlim(lim.z[0],lim.z[1])
    ax.view_init(elev=elev,azim=azim)
def get_camera_mesh(pose,depth=1):
    vertices = torch.tensor([[-0.5,-0.5,-1],
                             [0.5,-0.5,-1],
                             [0.5,0.5,-1],
                             [-0.5,0.5,-1],
                             [0,0,0]])*depth
    faces = torch.tensor([[0,1,2],
                          [0,2,3],
                          [0,1,4],
                          [1,2,4],
                          [2,3,4],
                          [3,0,4]])
    vertices = cam2world(vertices[None],pose)
    # vertices = vertices[None]
    wireframe = vertices[:,[0,1,2,3,0,4,1,2,4,3]]
    return vertices, faces, wireframe
def vis(pose, pose_ref):
    cam_depth = 0.5
    _, _, cam = get_camera_mesh(pose, depth=cam_depth)
    _, _, cam_ref = get_camera_mesh(pose_ref, depth=cam_depth)
    
    color = (0,0.6,0.7)
    ref_color = (0.7,0.2,0.7)
    
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    setup_3D_plot(ax,elev=45,azim=35,lim=edict(x=(-3,3),y=(-3,3),z=(-3,2.4)))
    plt.subplots_adjust(left=0,right=1,bottom=0,top=0.95,wspace=0,hspace=0)
    plt.margins(tight=True,x=0,y=0)
    
    N = len(cam)
    
    ################################ poses 1 #################################
    ax.add_collection3d(Poly3DCollection([v[:4] for v in cam],alpha=0.2,facecolor=color))
    for i in range(N):
        ax.plot(cam[i,:,0],cam[i,:,1],cam[i,:,2],color=color,linewidth=1)
        ax.scatter(cam[i,5,0],cam[i,5,1],cam[i,5,2],color=color,s=20)
    ################################ poses 2 #################################
    ax.add_collection3d(Poly3DCollection([v[:4] for v in cam_ref],alpha=0.2,facecolor=ref_color))
    for i in range(N):
        ax.plot(cam_ref[i,:,0],cam_ref[i,:,1],cam_ref[i,:,2],color=ref_color,linewidth=0.5)
        ax.scatter(cam_ref[i,5,0],cam_ref[i,5,1],cam_ref[i,5,2],color=ref_color,s=20)
    ################################ translation error #################################    
    for i in range(N):
        ax.plot([cam[i,5,0],cam_ref[i,5,0]],
                [cam[i,5,1],cam_ref[i,5,1]],
                [cam[i,5,2],cam_ref[i,5,2]],color=(1,0,0),linewidth=3)
    png_fname = "xxx.png"
    plt.savefig(png_fname,dpi=75)
    # 显示图形
    plt.show()
if __name__ == '__main__':
    d1 = "output/lego/hidden256_near2_far6/test/"
    d2 = "output/lego/hashnerf_fuck_resolution_newnerf_accmap/test/"
    output_file = "comparison_video.mp4"
    image_directory = "./"

    generate_comparision_video(d1, d2)
